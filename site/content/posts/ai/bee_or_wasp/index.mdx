---
title: "AI 미니 프로젝트 - 꿀벌과 말벌 구분하기"
category: "AI"
author: kuper0201
tags: ['#AI', '#CNN', '#projects']
date: 2022-03-02
slug: bee-or-wasp
thumbnail: cover.jpg
draft: true
---

## 서론

최근 말벌의 습격으로 인해 양봉 농가의 피해가 극심하다는 소식을 심심치 않게 들을 수 있습니다. 말벌의 종류에 따라 다르긴 하지만 기본적으로 말벌은 꿀벌보다 몸집이 크고 힘이 세기 때문에 인간의 개입 없이 말벌의 습격을 막아내기란 쉬운 일이 아니라고 합니다. 하지만 인간이 항상 상주하고 있을 수 없기 때문에 필자는 기술적으로 해결할 수 있는 방안을 생각해 보게 되었고 말벌을 Detecting 하는 AI 모델을 간단하게나마 구축해 보기로 하였습니다.

## 분류 모델 선택
분류 모델은 크게 이진 분류와 다중 분류 두 가지로 나눠집니다.

먼저 이진 분류는 모델의 결과값으로 참(True) 또는 거짓(False)을 반환하는 모델이고 다중 분류는 모델의 결과값으로 확률을 반환하는 모델입니다.

말벌과 꿀벌을 분류 할 때를 예로 들자면 A라는 이미지가 말벌이라면 참(True) 말벌이 아니라면 거짓(False)을 반환하는 모델은 이진 분류 모델이며 A라는 이미지가 말벌일 확률 M% 이미지가 꿀벌일 확률 N% 이미지가 개미일 확률 K% ... (모든 반환값을 더했을 때 100%) 처럼 확률을 반환해 주는 모델은 다중 분류 모델입니다.

이진 - 말벌이라면 True / 그 외의 생물이라면 False

다중 - 말벌일 확률 / 꿀벌일 확률 / 개미일 확률 ...

단순히 말벌과 꿀벌을 분류하고 알림을 주기 위해서는 이진 분류 모델을 구축하는 것이 이상적이지만 본 프로젝트에서는 노이즈 데이터 또한 이용하고 말벌과 서식지가 겹치는 다른 생물들 또한 분류하기를 원했기 때문에 다중 분류 모델을 채택하게 되었습니다.

### 데이터셋

모델을 구축하기 위해서 가장 먼저 필요한 것은 말벌과 꿀벌 그리고 그 외의 생물들의 이미지 데이터를 확보하는 것 입니다. 다행히도 웹에서 크롤링할 필요 없이 [Kaggle](https://www.kaggle.com)에서 말벌과 꿀벌의 이미지를 제공하는 [Bee or Wasp?](https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp) 저장소를 찾을 수 있었습니다. 해당 저장소의 목적 또한 말벌과 꿀벌을 분류하는 모델을 구축하는 것이 목적이기에 본 프로젝트에 사용하기에는 더할나위 없이 좋은 데이터라고 생각했습니다.

하지만 Bee or Wasp?의 데이터셋은 이미지의 개수가 12000여 장으로 볼륨이 작고 외국의 데이터셋이기 때문에 국내 생물들의 특성은 반영하지 못하는 경향을 보였습니다. 따라서 크롤링을 통해 국내종들의 데이터를 확보하고 이미지 증강 기법을 통해 30000여 장으로 데이터셋의 볼륨을 키워 재구축 하였습니다.

이 중 약 20%인 6000여 장의 이미지는 검증 데이터셋으로 사용하였습니다.

데이터셋의 라벨은 Bee / Wasp / Other Insect 로 나누었습니다.

Bee에는 꿀벌의 이미지들이 저장되어 있고 Wasp에는 말벌의 이미지가 저장되어 있습니다. 또한 Other Insect에는 꿀벌과 서식지가 겹치는 개미, 잠자리, 나비 등의 이미지들이 저장되어 있습니다. 마지막으로 Other에는 꽃, 강아지, 고양이 등의 곤충이 아닌 다른 사물들의 이미지들이 저장되어 있습니다.

다음으로는 각 라벨별 이미지 데이터를 시각적으로 확인해 보겠습니다.

## 이미지 확인

### Bee 라벨

[](이미지)

Bee 라벨의 이미지 25장입니다. 대부분의 이미지들이 꽃과 함께 있는 꿀벌 이미지이므로 학습이 완료 된 후 꿀벌이 없는 꽃 데이터를 예측 할 때 잘못된 예측을 할 수 있습니다. 따라서 Other 라벨에 꽃 데이터를 크롤링해 추가 해 주었습니다.

### Wasp 라벨

[](이미지)

Wasp 라벨의 이미지 25장입니다. 사용한 데이터셋이 외국의 데이터셋이기 때문에 국내에 서식하는 말벌들의 데이터는 거의 존재하지 않아 크롤링을 통해 등 검은 말벌, 쌍쌀벌 등검은 말벌 등 국내에 서식하고 꿀벌에게 피해를 끼친다고 알려진 말벌들의 데이터를 추가 해 주었습니다.

### Other Insect 라벨

[](이미지)

Other Insect 라벨의 이미지 25장입니다. 말벌과 꿀벌이 아닌 곤충들의 이미지를 가지고 있습니다. 모든 곤충들의 데이터를 추가하는 것은 불가능 하므로 최대한 나비, 잠자리, 거미 등 꿀벌과 서식지가 겹치는 곤충들의 이미지를 크롤링을 통해 추가해 주었습니다.

### Other 라벨

[](이미지)

마지막으로 Other 라벨의 이미지 25장입니다. 자동차와 강아지, 사람의 사진 등 곤충과는 관계가 없는 데이터를 가진 것을 확인 할 수 있습니다.

## 모델 구축

파이썬과 텐서플로우를 이용해 모델을 구현한 코드입니다.

<details markdown="1">
<summary>코드 보기(Python)</summary>

```javascript
import pathlib
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from keras.utils import image_dataset_from_directory

data_dir = '데이터셋 경로'
data_dir = pathlib.Path(data_dir)

test_dir = '테스트 데이터 경로'

image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count)

# 1
batch_size = 200
img_height = 180
img_width = 180
EPOCHS = 50
num_classes = 4
drop_out = 0.5

def getDataSet(subset):
    return image_dataset_from_directory(data_dir, validation_split=0.2, subset=subset, seed=123, image_size=(img_height, img_width), batch_size=batch_size)

train_ds = getDataSet("training")
val_ds = getDataSet("validation")

test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir, image_size=(img_height, img_width), batch_size=1)

# 4
class_names = train_ds.class_names

drop = 0.4 # DropOut 비율 설정

model = tf.keras.Sequential()
model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255))
model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(180, 180, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(drop))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(drop))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(drop))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

checkpoint = ModelCheckpoint('check_point', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')
earlystopping = EarlyStopping(monitor='val_loss', patience=5)

model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

# 학습 안하고 테스트시 아래 세 줄 주석처리 할 것
#model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[checkpoint, earlystopping])
#model.load_weights('check_point') # 체크포인트에 저장된 최상의 모델 불러오기
#model.save('/Users/jeongjunsu/Desktop/model')

model = tf.keras.models.load_model('모델 저장 경로')
#model.evaluate(val_ds)

r = model.predict(test_ds)
print(class_names)
print(r)
print(class_names[np.argmax(r)])
```
</details>

## 모델 설명

[](이미지)

본 모델의 구조는 그림과 같습니다. 데이터를 입력받고 정규화 하기 위한 입력층 이미지의 특징을 추출 할 은닉층 4층, 실제로 데이터를 분류하여 출력해줄 출력층 으로 총 6개의 층, 17레이어로 이루어져 있습니다.

입력층인 맨 처음 Rescailing층에서는 데이터를 입력받고 정규화를 하기 위해 입력 받은 데이터의 픽셀 값을 0에서 255 사이의 값으로 변환하도록 하였습니다.

은닉층에서는 더욱 세세한 이미지의 특징을 추출 할 수 있도록 Convolution, MaxPooling, DropOut 레이어의 순서로 총 4개의 층을 추가했습니다.

마지막 출력층에서는 추출된 특징들을 가지고 데이터를 분류할 수 있도록 평면화 작업을 한 뒤 데이터의 과적합을 막기 위해 Dense 층을 이용해 L2 규제를 적용하고, 드롭아웃 층을 추가해 주었습니다.

### 과적합 방지 전략

본 모델에서 과적합을 방지하기 위해 사용한 전략은 다음와 같습니다.

먼저, Early Stop을 이용해 10 에폭동안 검증 오차의 개선이 없을 시 학습을 종료하게 하였습니다. 다음으로 DropOut을 적용하여 특정 노드가 모델에 과도한 영향을 끼치는 것을 방지하였습니다. 마지막으로, L2 규제를 적용하여 가중치를 제한해 모델이 몇 개의 가중치에만 과도한 영향을 받는 것을 방지하였습니다.

## 모델의 성능 분석

[](이미지)

모델의 성능을 분석해 보겠습니다. 상단의 이미지는 검증 데이터셋을 이용한 모델의 평가 수치입니다.

보시는 것처럼 본 모델은 0.908의 Accuracy와 0.359의 오차를 달성 하였습니다.

다음으로 모델의 Accuracy 그래프를 확인해 보겠습니다. 대략 30번째 에폭 이후부터 train 데이터셋은 계속 적합이 진행되지만 test 데이터셋은 더 이상 적합이 진행되지 않는 것이 보입니다. 

마지막으로 모델의 Loss 그래프를 확인해 보겠습니다. Accuracy 그래프와 마찬가지로 32번째 에폭에서 가장 작은 오차율을 달성하고 이후 과적합이 진행되는 그래프가 보여집니다.

그래프의 분석 결과 32번째 이후로는 과적합이 진행되는 양상을 보인다는 것을 알 수 있습니다.

따라서 본 프로젝트에서는 과적합이 일어나기 직전 오차율이 가장 작았던 32번째 에폭의 모델을 최종 모델로 선정하였습니다.

## 예측 결과 확인

[](이미지)

구축한 모델이 제대로 예측을 하는지 예측 결과를 확인해 보겠습니다. 51개의 데이터를 예측하였고 각 이미지 아래에 있는 라벨은 모델이 예측한 값을 의미합니다. 모델의 예측이 맞았을 경우 청색으로 출력되게 하였고 틀렸을 경우에는 적색으로 출력되게 하였습니다.

대부분의 데이터는 정확히 예측을 하였지만 틀린 예측을 한 데이터가 있다는 것을 볼 수 있습니다.

틀린 예측을 한 데이터는 모기의 이미지이고 나비, 잠자리 등의 다른 데이터들은 other insect 라벨에 추가해 주었지만 모기의 데이터는 따로 추가하지 않았기 때문에 잘못된 예측을 한 것을 볼 수 있습니다. 물론 이는 다른 곤충들의 데이터를 더 추가하면 해결 될 수 있지만 모든 곤충들의 데이터를 추가하는 것은 불가능하기 때문에 바람직한 방법은 아닙니다.

## 개선 방안

상기하였듯 데이터를 무한히 추가하는 것은 불가능 하기에 더 효율적인 방식을 생각해 보았습니다. 여러 이진 분류 모델들의 앙상블입니다.

[](이미지)

이미지는 이진 분류 모델의 앙상블을 시각적으로 표현한 것 입니다.

맨 처음의 이진 분류 모델은 곤충인지 아닌지에 대한 결과를 예측하고 곤충이 아닐 경우 다음 분류 모델에 데이터를 전송하지 않습니다. 곤충이 맞다면 다음 모델에 데이터를 전달하여 다른 곤충인지 벌인지를 예측합니다. 여기에서도 벌이 아니라면 다음 모델에 데이터를 전달하지 않고, 벌이 맞다면 다음 모델에 전달하여 꿀벌인지 말벌인지에 대한 예측을 진행하여 최종 결과를 출력하게 됩니다. 이런 앙상블 방식을 이용하면 무한한 데이터의 추가 없이도 곤충의 특징 / 벌의 특징 / 말벌과 꿀벌의 특징 을 추출하여 비교적 정확한 예측을 가능하게 할 것으로 생각됩니다. 이는 현재 분류학에서 사용하는 방식과 유사하므로 더욱 직관적인 분류를 가능하게 합니다.