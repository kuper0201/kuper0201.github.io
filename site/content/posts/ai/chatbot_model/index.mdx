---
title: "AI 자기소개 챗봇 만들기 - 2. 모델 구현"
category: "인공 지능"
author: kuper0201
tags: ['#AI', '#NLP', '#projects']
date: 2022-03-02
slug: ai-chatbot-model
thumbnail: cover.jpg
draft: true
---

import "katex/dist/katex.min.css";

## 바로가기

### &nbsp; &nbsp; &nbsp; &nbsp;[AI 자기소개 챗봇 만들기 - 1. 전처리](/ai-chatbot-preprocess)
### &nbsp; &nbsp; &nbsp; &nbsp;[AI 자기소개 챗봇 만들기 - 2. 모델 구현(현재 글)](#서론)
### &nbsp; &nbsp; &nbsp; &nbsp;[AI 자기소개 챗봇 만들기 - 3. Django 배포](/ai-chatbot-deploy)

---

## 서론

&nbsp;&nbsp; 이전 글에서는 NLP를 위한 첫 단계인 토큰화에 대해 설명하였습니다. 이번 글에서는 프로젝트에 적합한 NLP 모델을 선정하고 이를 이용해 입력된 질문에 대한 답변을 생성하는 파이프라인을 구축해 보도록 할 것입니다.

## 모델 선정

현재 NLP 분야에는 작업의 형태와 목적에 따른 다양한 모델이 존재하므로 모델의 선정을 위해서 프로젝트에서 원하는 작업의 형태와 목적을 정확히 정해야 합니다.


---
---


## 서론

&nbsp;&nbsp; 이전 글에서는 형태소 단위의 임베딩을 설명하였고, 프로젝트에서도 이를 활용하여 키워드의 유사도를 비교해 적합한 응답을 매칭하는 방식을 고려하였지만 진행 과정에서 예상치 못한 문제점이 발생하였습니다.

"취미가 무엇인가요?"라는 질문과 "여가 시간에 주로 무엇을 하나요?"라는 질문을 가정해 보겠습니다.
두 질문은 서로 다른 단어를 사용하지만 실제로는 유사한 의미를 가지므로 "저의 취미는 알고리즘 문제 풀기입니다."라는 응답을 기대하였습니다. 하지만 키워드 매칭 방식은 문맥을 고려하지 않기 때문에 두 질문간의 유사성을 인식하지 못하고 잘못된 응답을 하는 문제가 발생하였습니다.

물론 질문/응답 데이터셋에 수동으로 다양한 어휘의 동일한 질문을 추가하는 방식으로 해결이 가능하지만, 이는 모든 어휘에 대응이 불가능하다는 점에서 근본적인 문제의 해결이 불가능합니다. 따라서 키워드 매칭 방법은 최종적으로 제외하였고, 문맥의 고려가 가능한 고차원 모델 도입의 필요성을 실감하여 다양한 모델을 구현하고 비교하였습니다.

## 모델 비교 및 선정

다음은 본 프로젝트에서 테스트한 주요 모델과 결과입니다. 각 모델의 특성과 성능을 비교해 최종적으로 XLM-RoBERTa를 선정한 과정을 단계적으로 설명합니다.

1. Seq2Seq
	- 구조: 질문을 인코딩하고, 응답을 디코딩하여 생성하는 방식.
	- 장점:
		- 다양한 질문에 유연하게 대응 가능.
		- 데이터를 기반으로 자연스러운 문장 생성이 가능.
	- 단점:
		- 미리 정의된 응답과의 매칭 정확도가 낮음.
		- 할루시네이션 문제: 입력과 무관한 새로운 응답 생성 빈도가 높음.

2. Transformer
	- 구조: 질문과 응답을 각각 임베딩하고, 코사인 유사도를 계산해 최적의 응답을 선택.
	- 장점:
		- 셀프 어텐션(Self-Attention) 메커니즘으로 문맥을 효과적으로 이해.
		- Seq2Seq 모델 대비 응답 매칭 정확도가 높음.
	- 단점:
		- 일부 질문에서 간헐적인 할루시네이션 문제 발생.
		- 사전 정의된 응답과의 매칭 정확도는 XLM-RoBERTa에 비해 낮음.

3. XLM-RoBERTa
	- 구조: 사전 학습된 다국어 모델로, 뛰어난 문맥 이해와 임베딩 품질을 제공.
	- 장점:
		- 미리 정의된 응답 세트와의 매칭에서 가장 높은 정확도를 기록.
		- 할루시네이션 문제를 거의 완전히 해결하며, 안정적이고 일관된 결과 제공.
	- 단점:
		- 메모리 사용량이 높아 리소스 관리에 주의가 필요.
	
## 할루시네이션 문제와 해결 과정

할루시네이션 문제는 NLP 모델에서 중요한 도전 과제 중 하나입니다. 이는 모델이 질문과 무관한 응답을 생성하는 현상으로, 특히 Seq2Seq 모델에서 두드러지게 나타났습니다.
	•	Seq2Seq 모델은 응답 생성의 유연성은 높지만, 입력된 질문과 사전 정의된 데이터 간의 매칭보다는 새롭고 창의적인 응답을 생성하려는 경향이 강했습니다.
	•	Transformer 기반 모델에서는 문맥 이해도가 향상되었지만, 일부 질문에서 여전히 예측하지 못한 응답이 발생했습니다.

XLM-RoBERTa는 코사인 유사도 기반의 응답 선택 방식을 채택해 이러한 문제를 해결했습니다. 질문과 응답 간의 문맥적 유사도를 평가해, 미리 정의된 응답 중 가장 적합한 결과를 반환함으로써 사용자가 신뢰할 수 있는 응답을 제공할 수 있었습니다.

## 성능 비교

아래는 테스트 결과를 정리한 표입니다.

모델	정확도	주요 문제	장점
Seq2Seq	67%	할루시네이션 문제 심각	유연한 응답 생성
Transformer	81%	간헐적 할루시네이션 발생	문맥 이해와 높은 성능
XLM-RoBERTa	93%	할루시네이션 문제 해결	높은 문맥 이해와 응답 매칭 정확도

Mecab과의 연계 및 적용

이전 글에서 다룬 Mecab 기반 유사도 측정 방식은 초기에 효율적인 매칭 방법으로 고려되었으나, 아래와 같은 한계로 인해 최종 구현에서 제외되었습니다:
	•	문맥 이해 부족: 단순 키워드 매칭으로는 문맥적인 질문과 응답 연결이 어려웠음.
	•	확장성 부족: 복잡한 문장 구조나 유사 표현을 처리하는 데 한계가 있었음.

그러나 Mecab으로 텍스트를 전처리한 데이터는 Transformer 및 XLM-RoBERTa 모델의 성능을 향상시키는 데 기여했습니다. 특히, 형태소 분석을 통한 데이터 정제는 모델 학습과 응답 매칭 정확도를 높이는 중요한 과정이었습니다.

결론: XLM-RoBERTa 선정 이유

테스트 결과, XLM-RoBERTa는 미리 정의된 자기소개 응답과의 매칭에서 가장 높은 정확도를 보였으며, 할루시네이션 문제를 해결하는 데 가장 효과적이었습니다. Seq2Seq 및 Transformer 모델은 각각 응답 유연성과 문맥 이해에서 강점을 보였으나, 할루시네이션 문제로 인해 적합하지 않았습니다.
XLM-RoBERTa는 질문의 문맥을 깊이 이해하며, 사전 정의된 응답 데이터와의 매칭에서 일관성과 신뢰성을 동시에 제공합니다.

다음 단계: Django를 활용한 배포

다음 글에서는 XLM-RoBERTa 기반의 챗봇을 Django 프레임워크를 통해 웹 애플리케이션으로 배포하는 과정을 다룰 예정입니다. 이를 통해 사용자와의 인터페이스를 구축하고, 실제 환경에서 챗봇을 운영할 수 있는 방법을 소개하겠습니다.
앞으로도 프로젝트에서 얻은 실험 결과와 경험을 공유하며, 실질적으로 도움이 되는 인사이트를 제공하겠습니다. 🚀

추가 개선 사항이나 특정 포인트에 대한 설명이 필요하면 말씀해주세요!